\chapter{Fazit}
Ziel dieser Arbeit war die Entwicklung und Implementierung sowie die anschließende Evaluation eines Lastverteilers auf einer DPU. Dazu wurde die BlueField-3 als Plattform gewählt. Es wurden unterschiedliche Bereiche der Hardwarearchitektur von NVIDIA analysiert und dazu relevante Forschungsfragen formuliert. Es konnte im Vergleich zu anderen Softwarelastverteilern eine erheblich höhere Durchsatzrate gezeigt werden. Der Lastverteiler ist ein Proof-of-Concept, welches beweist, dass es durchaus möglich ist, Anwendungen sinnvoll auf einer Smart NIC zu implementieren. Allerdings ist dies nur mit einer tieferen Analyse der Schnittstellen und der Hardware möglich, um innerhalb der Implementierung von den gegebenen Hardwarebeschleunigern Gebrauch machen zu können und eventuell auftretenden Bottlenecks aus dem Wege zu gehen.
\section{Versprechen der Zero-Overhead-Verarbeitung}
Das Versprechen seitens NVIDIA, dass der vollständige Netzwerkverkehr ohne Overhead und vor allem ohne Paketverlust verarbeitet werden kann, ließ sich so nicht reproduzieren. Es war in den Versuchen, bei denen Last auf den Lastverteiler XenoFlow ausgeübt wurde, keine Veränderung der Latenz messbar. Allerdings wurde bei einer Paketrate von ca. 95 - 98 Millionen Paketen pro Sekunde nicht mehr der komplette Datenverkehr verarbeitet. Es kam zu erheblichen Paketverlusten. Positiv festzustellen ist allerdings, dass die Paketgröße fast vollständig von der Paketverarbeitungsrate abhängt. Somit ist die Behauptung seitens NVIDIA als nicht allgemein gültig zu betrachten.
\section{Einfluss der Paketgröße auf den Datendurchsatz}
Die beworbenen 400 Gbit/s Datendurchsatz konnten in unseren Experimenten nicht erreicht werden. Dazu sei erwähnt, dass das verwendete Netzwerk aufgrund der in den Testknoten verbauten Netzwerkkarten einen Durchsatz von 100 Gbit/s hatte. Aber auch dieser Wert ließ sich nur ab einer Paketgröße von über 1024 Bytes erreichen. Dabei handelt es sich um eine Paketgröße, welche im Kontext der Verwendung mit den meisten Anwendungen eher untypisch ist. Klassische Paketgrößen kommen selbst bei einer vollständigen Hardwareauslagerung auf eine Bandbreite von nicht mehr als 64 Gbit/s (siehe Abbildung 7.4).
\section{Einfluss der Last auf die Round-Trip-Time}
Es konnte nachgewiesen werden, dass die Auslastung der Hardwareports sowie der DPA-Architektur keinen messbaren Einfluss auf die Verarbeitungslatenz sowie Round-Trip-Time hat. Dazu wurde der Vergleich von mehreren Lastverteilungsszenarien durchgeführt. Somit konnte diese Behauptung des Herstellers als richtig erwiesen werden. Außerdem war es in dem Zuge, zwar mit Hürden, möglich, vollständigen Gebrauch der angepriesenen Hardwarebeschleuniger auf der BlueField-3 zu machen.  
\section{Ausblick}
Lastverteiler in Rechenzentren werden auch in den nächsten Jahrzehnten mit steigendem Interesse verfolgt werden. So zeigen etwaige Cloud-Anbieter wie Amazon, Google oder Microsoft sehr großes Interesse an Lastverteilungslösungen.
Der XenoFlow-Lastverteiler ist zum Zeitpunkt der Abgabe dieser Arbeit in der Lage, UDP-Pakete auf eine Anzahl von fest definierten Servern anhand ihrer MAC-Adresse zu verteilen. Dabei ist derzeit insbesondere keine dynamische Anpassung der verfügbaren Endpunkte möglich. Eine interessante Weiterentwicklung könnte es also sein, XenoFlow um einen Mechanismus zu erweitern, der es ihm ermöglicht, die Backends, an die weitergeleitet werden soll, anzupassen. Dazu wäre eine weitere Kommunikationsebene denkbar, auf der XenoFlow mit den Endpunkten kommunizieren kann. Somit wären die Endpunkte in der Lage, ihren aktuellen Zustand mit XenoFlow abzustimmen, damit dieser intelligentere Lastverteilungsentscheidungen fällen könnte. Dazu wäre ein Algorithmus denkbar, der dynamisch in Erfahrung bringt, ob der Quell-IP-Adresse bereits ein Backend zugeordnet wurde. Ist dies nicht der Fall, so wird ein neues Backend gewählt. Es könnte für jedes Backend eine eigene Pipe oder ein entsprechendes Entry angelegt werden. Welche dieser Arten die schnellere und effizientere ist, wäre abermals eine spannende Frage für kommende Arbeiten. Diese Art der Lastverteilung wäre deutlich dynamischer im Vergleich zum aktuellen statischen Klassifizieren von IP-Adressen in XenoFlow.

Außerdem wäre es interessant, XenoFlow um das Protokoll TCP zu erweitern. TCP wird von wesentlich mehr Applikationen verwendet. Dazu müsste allerdings eine Art und Weise entwickelt werden, wie mit offenen Verbindungen o. ä. auf dem XenoFlow-Lastverteiler gearbeitet wird. Zudem wäre ein Einsatz in Edge-Computing oder Kubernetes-Clustern denkbar und bietet daher verschiedene Ansätze, wie XenoFlow zum Einsatz kommen kann.

Unabhängig von XenoFlow können aber auch andere Anwendungen auf der DPU implementiert werden. Es konnte eine starke Leistungssteigerung mittels ASIC-Verwendung gezeigt werden, was die Hoffnung bestärkt, dass auch andere Programme davon profitieren können. Energieeffizientes Rechnen ist ein hochaktuelles Thema und wird auch in den kommenden Jahrzehnten eine maßgebliche Thematik der Rechenzentren und somit der Informatik bleiben.