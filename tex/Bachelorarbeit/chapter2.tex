%
% chapter2.tex
%

\chapter{Smart NICs - ein Überblick}
\label{cha:background}

\section{Begriffserklärung}
Der Begriff Smart NIC ist wie allzu oft in der Computerwissenschaft mit einer Menge von Definitionen versehen. Grundsätzlich beschreibt eine \textbf{\textit{smart network interface card}} eine Hardwareeinheit, die sich mit der Netzwerkfähigkeit eines Rechners beschäftigt. Dabei unterscheidet sie sich von den klassischen Netzwerkkarten in der Hinsicht, dass wir als Anwender beziehungsweise Entwickler im Kontext dieser Karte Anwendungen schreiben können, die das Verhalten der Karte beeinflussen. Dabei ist nicht fest definiert, welche Funktion oder überhaupt in welchem Umfang Programmierung stattfinden kann. Nicht zuletzt ist das immerwährende Aufkommen des Begriffs Smart* dafür verantwortlich, dass sicherlich auch aus Marketinggründen ein etwaiger Name gewählt wurde. Allgemein lässt sich aber sagen, dass eine Smart NIC eine Netzwerkkarte ist, die es uns erlaubt, Anwendungen für eben diese zu erstellen, die ihr eigenes Verhalten derart verändern kann, dass Funktionen, die sonst innerhalb eines Netzwerkstapels übernommen werden würden.

\section{Aufbau und Funktionsweise}
Smart NICs verwenden unterschiedliche Hardwarearchitekturen, um eine Hardwarebeschleunigung zu realisieren. Allgemein gab es sogar, gerade zu Zeiten des Aufkommens von derartigen Rechnern, in den 90er- und frühen 2000er-Jahren, Smart NICs, die lediglich oder größtenteils klassische Prozessorarchitekturen wie RISC oder x86 verwendeten, um die Funktionalität zu gewährleisten. Mit Anbruch des neuen Jahrtausends jedoch zogen immer mehr FPGA- und ASIC-basierte Architekturen in die Rechenzentren ein.
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{images/GrundaufbauSmartNIC.drawio.png}
    \caption{Einfaches ändern einer IP Adresse im Paket}
    \label{fig:enter-label}
\end{figure}
Das steigende Interesse an der SmartNIC Architektur ist nicht zuletzt durch den abflachenden Leistungsgewinn durch Generationsfortschritte in der Prozessorindustrie befeuert worden. Mittlerweile gilt das Moorsche Gesetz als beendet und ein Großteil der Computerkommunikation heutzutage ist ohnehin Netzwerkverkehr. Meistens werden dazu TCP- und UDP-Pakete verwendet. Werden diese Pakete auf Prozessoren verarbeitet, sind die entsprechenden Kosten nicht nur hardware-, sondern auch energieseitig sehr hoch. Zuletzt hat nun auch der Aufschwung der modernen Softwarearchitekturen für einen explosionsartigen Anstieg in Netzwerkverkehr gesorgt. Wurden vor 20 Jahren Anwendungen noch so entwickelt, dass möglichst wenig Kommunikation über ein Netzwerk läuft, wird in heutigen Systemen stark und immer mehr auf eine Microservice-basierte Architektur gesetzt. Dabei wird eine komplexe Applikation in verschiedene Bereiche unterteilt, die daraufhin mittels HTTP angebundenen Interfaces miteinander kommunizieren. Grund dafür ist die Idee der vereinfachten Wartbarkeit von kleinteiligen Applikationen.
Zu Beginn der Entwicklung besagter Hardware war zunächst grundsätzlich die Idee, die programmierbare Funktionalität auf dem Switch, also dem Anbindungspunkt des Rechenzentrums, umzusetzen. Allerdings steigt mit der Anzahl der Knoten im Teil hinter dem Switch auch die benötigte Rechenkapazität des Switches. Daher hat sich ein eher dezentraler Ansatz entwickelt, bei dem in dem Server selbst eine Karte integriert ist, auf der sich ein zusätzlicher Rechner befindet. Dabei ist die Verbindung zugunsten der größten Kompatibilität meist mittels PCI Express umgesetzt. In der Abbildung 2.1 ist ein grundsätzliches Diagramm eines hier erstmal abstrahierten Datenpakets dargestellt. Der Client schickt ein Paket mit einer bestimmten Ziel-IP-Adresse los und zu einem gewissen Zeitpunkt erreicht das Paket die Smart NIC. Diese wendet daraufhin eine Aktion an. In diesem Fall wird die Ziel-IP-Adresse geändert und zurück in das Netzwerk geleitet. Dadurch bekommt nun ein anderer Server das Paket. Hierbei ist interessant, dass die Umleitung dem Client verborgen bleibt. Im Prinzip handelt es sich also bei dem gezeigten Beispiel um einen primitiven L3-Proxy.
\subsection{Hardwareaufbau}
SmartNICs sind in aller Regel im Grunde völlig eigenständige Systeme, mit einer Prozessoreinheit, Arbeitsspeicher und teilweise sogar eigenständiger Netzwerkein- und -ausgabe über einen separaten Hardwareport. Die Idee dabei ist es, ein System zu schaffen, auf dem eigenständig Applikationen ausgeführt werden können, aber auch Dienste wie Docker oder Kubernetes angewendet werden können. So wird auch die Verbindung zur Entwicklung über etwaige Dienste wie SSH hergestellt. Allerdings bieten auch einige Hersteller eigenständige Lösungen an, welche in aller Regel mittels \textbf{\textit{Application Programming Interfaces}} kurz APIs zur Verfügung gestellt werden. Hauptgrund ist allerdings wie so oft in solch hochkritischen Systemen Sicherheitsbedenken. Eine vollständig getrennte Einheit unterstützt in diesem Sinne das Konzept der Zero-Trust-Paradigmen. Dabei ist die Grundannahme, dass alle Kommunikationspartner sowie alle Beteiligten in einem System nicht zu vertrauen ist. Eine SmartNIC kann somit völlig autark in einem Netzwerk fungieren, ohne dass das Hostsystem selbst den Aufbau des Netzwerks oder dessen Funktionsweise kennt. Die besonders im Kontext der Netzwerkverarbeitung relevanten Hardwareeinheiten werden mittels fest verarbeiteter Hardwareinterfaces angesprochen. Dabei werden meist die vorliegenden PCI Lanes als Hochgeschwindigkeitsverbindung genutzt. Und genau hier wird auch einer der größten Unterscheidungspunkte zwischen der klassischen Netzwerkpaket verarbeitenden Hardware und den SmartNICs deutlich. Die meisten anderen Netzwerkadapter verwenden klassische Mikrocontroller, um eine Konfigurierbarkeit zu gewährleisten. Die Kommunikation zwischen den Mikrocontrollern und den tatsächlichen Hardwarebeschleunigern findet daraufhin meist mittels serieller Schnittstellen statt. Dabei ist natürlich das Hauptunterscheidungsmerkmal unter anderem der Prozessortakt. Klassische SmartNIC \textbf{\textit{Systems on a Chip}} kurz SoC verwenden Prozessoren mit mehreren Kernen, die in einem ähnlichen Bereich getaktet sind wie etablierte Server- oder Desktopchips. Dabei ist die Leistung vor allem relevant, da auch klassische Berechnung auf den Kernen ausgeführt werden sollen. Bei den kleineren, schwächeren Mikrocontroller-Prozessoren liegen die Taktraten größtenteils klar unter 1 GHz. Diese werden allerdings auch eben nur für Konfiguration und Management verwendet und übernehmen keine direkte Aufgabe, die an der Paketverwaltung beteiligt ist. Zusammenfassend lässt sich also eine grobe Unterteilung vornehmen, bei der die SoC Varianten von SmartNICs klar von denen unterscheiden die diskrete Hardwareeinheiten für den jeweiligen Verwendungszweck besitzen.
\subsection{Path Switching}
Über die letzten Jahre haben sich unter diversen anderen architektonischen Ansätzen zwei etabliert, welche für den Kontext dieser Arbeit von besonderer Bedeutung sind. Dabei wird die hauptsächliche Unterscheidung dadurch getroffen, dass unterschieden wird, wo genau die Switching-Funktionalität stattfindet. Es wird grundsätzlich zwischen On-Path-Switching und Off-Path-Switching unterschieden.
\subsubsection{On-path SmartNICs}
Bei einer On-Path SmartNIC verhält sich die Netzwerkkarte sehr nahe an der Funktionsweise, wie man sie von einer traditionellen Netzwerkkarte erwarten würde. Pakete, die über das Kabel an die Hardware herantreten, werden zunächst von dem entsprechenden Stack der Karte verarbeitet und laufen gezwungenermaßen nicht nur über den Traffic-Manager, sondern insbesondere auch über die Kerne der SmartNIC. Das heißt zwar, dass ein nicht unerheblicher Overhead bei der Verarbeitung des Datenverkehrs im Kernel des Betriebssystems der Netzwerkkarte entsteht, ermöglicht es aber eben auch, Modifikationen an besagten Paketen vorzunehmen. Dabei steht aber vor allem auch die vereinfachte Entwicklung solcher Netzwerkkarten im Vordergrund. Sollte es sich wiederum um eine On-path SmartNIC handeln bei der Paket direkt über den Kernel des Hostrechners verarbeitet werden stellt sich hierbei das Problem da, dass es so zu einer Überlastung der Anbindung zwischen SmartNIC und Host kommen kann. Außerdem liegt in solch einem Fall dann ein großteil der Rechenlast wieder beim Host, womit die eigentliche Funktionalität der SmartNIC stark abnimmt. 
\subsubsection{Off-path SmartNICs}
Bei Off-Path SmartNICs handelt es sich hingegen um Geräte, bei denen eine klarere Trennung der Hardwareeinheiten vernommen wird. Eben diese Trennung ermöglicht es, eine Spezialisierung vorzunehmen, mit der für bestimmte Anwendungszwecke besondere Hardwarebeschleuniger verbaut werden können. Eben genau diese Architektur erlaubt es, einen wesentlich größeren Anwendungsbereich abzudecken, da dadurch eine große Flexibilität für die Verarbeitung von Datenpaketen gewährleistet wird. Wenn ein Paket eintrifft, muss es nicht von einem Prozessorkern der Netzwerkkarte beachtet werden, sondern kann von der speziellen Hardwareeinheit verarbeitet werden. Dabei werden in aller Regel \textbf{\textit{Application Specific Integrated Circuits}} kurz ASICs verwendet. Die Konfiguration dieser ASICs erfolgt dann meistens mittels Software die auf dem Prozessor der Netzwerkkarte. Allerdings gibt es dort auch Unterscheidungen ob die Anwendung zur Konfiguration auf dem Hostsystem, also dem Rechner in dem die SmartNIC eingebaut ist oder der Karte selbst ausgeführt werden soll. Off-path SmartNICs verbessern somit die gesamt Architektur indem sie die Allgemeinen Kerne des Prozessors klar vom kritischen Pfad der Netzwerkpakete trennen und es so verhindern, dass die logische Last, welche mit einer Anwendung einhergehen kann, sich in keinster Weise auf den tatsächlichen Durchsatz der Netzwerkkarte auswirken können.
\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{images/Screenshot 2025-03-16 at 10-41-14 Netdev 0x14 -- Taking Control of your SmartNIC v1.pdf.png}
    \caption{On-Path vs. Off-Path-Switching}
    \label{fig:enter-label}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{images/Buffalo_IFC-ILP4_VIA_VT6306.jpg}
    \caption{Firewire ASIC - VIA CT6306}
    \label{fig:enter-label}
\end{figure}
\subsection{Application Specific Integrated Circuits}
ASICs sind Hardwareeinheiten, die ein sehr großes Anwendungsgebiet entwickelt haben. So werden sie nicht nur in Netzwerkbeschleunigern verwendet, sondern werden immer dann verwendet, wenn der Zweck der Hardware sich gut beschreiben lässt und somit keine große Varianz an Aufgaben von der entsprechenden Einheit übernommen werden muss. So wird es nämlich den entsprechenden Ingenieuren erlaubt, statt eines allgemeinen Rechners eine hochspezialisierte Einheit zu entwickeln, bei der die Merkmale einer klassischen Prozessorrecheneinheit vernachlässigt werden können. Dadurch ist eine wesentliche Effizienzsteigerung möglich, die es erlaubt, mit wesentlich weniger Energie die gleiche Leistung zu erzielen, wie es sonst eine vergleichbare Recheneinheit bewerkstelligen würde. Für rechenintensive Systeme hingegen lässt sich eben letzterer Nutzen, da somit der allgemeine Durchsatz angehoben werden kann und somit Systeme realisierbar sind, die mit der Anwendung klassischer Rechenwerke erheblich mehr Aufwand bedeuten würden. Zudem erzeugen solche Systeme deutlich mehr Abwärme und würden die Entwicklung somit auch vor ein thermodynamisches Problem stellen. Zuletzt sei noch erwähnt, dass der Überbegriff ASIC nur sehr allgemein ist und ähnlich wie bei Prozessoren noch keine Auskunft über die genaue Implementierung gibt. Es gibt viele Architekturen, die für ASICs zur Anwendung kommen, da eben auch die Gebiete weitreichend sind und sich sehr divers unterscheiden. In Abbildung 2.3 ist ein ASIC zu sehen, der die Kommunikation zwischen einem Prozessor und einem sogenannten FireWire-Anschluss eines Endgerätes realisiert. Es muss festgelegt sein, welcher Standard von Geräten mit besagtem Anschluss erwartet wird, und um den Prozessor des Hostgerätes zu entlasten, kommt gezeigter ASIC zum Einsatz.
Der Zeitgeist in der Computerwissenschaft färbte letztlich außerdem das immens steigende Interesse an Machine Learning ab. Proportional dazu stieg das Interesse an effizienterer Hardware an, da etwaige Lernprozesse extrem energie- und somit kostenaufwendig sind. Es zeigt sich aktuell ein gesteigertes Interesse daran, ASICs zu fertigen, die effiziente hochdimensionale Vektoroperationen umsetzen. 
\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{images/aisic.png}
    \caption{Vergleich unterschiedlicher Beschleuniger Ansätze}
    \label{fig:enter-label}
\end{figure}
Abbildung 2.4 zeigt deutlich, wenn auch etwas vage, dass ASICs, sowie alle anderen Architekturen in sich selbst nur leichtes Leistungswachstum aufzeigen. Verwenden wir allerdings unterschiedliche Architekturen, so gibt es doch enorme, wenn auch schwer quantifizierbare Unterschiede.
\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{images/lowpowerasic.png}
    \caption{KAIST LLM Accelerator}
    \label{fig:enter-label}
\end{figure}
\subsection{Speedup}
Im Allgemeinen werden die Leistungen in eine Metrik gegossen, damit ein objektiver Vergleich vorgenommen werden kann. Dazu entwickelte sich der allgemeine Speedup, der beschrieben wird durch:

\begin{equation}
\text{Speedup} = \frac{T_{\text{alt}}}{T_{\text{neu}}}
\end{equation}

Dabei ist:
\begin{itemize}
  \item $T_{\text{alt}}$ die Ausführungszeit vor der Optimierung bzw. der Vergleichshardware
  \item $T_{\text{neu}}$ die Ausführungszeit nach der Optimierung bzw. der Vergleichshardware
\end{itemize}
Im Folgenden wird der allgemeine Speedup verwendet, um einen Vergleich zwischen den unterschiedlichen Lastverteilungsarchitekturen aufzuzeigen.